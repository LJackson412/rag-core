# LLM Extractor & RAG App

A modular **Retrieval-Augmented Generation (RAG)** stack with two indexing pipelines (OCR-based and LLM extraction) and a two-stage retrieval process with LLM compression. The setup is designed for fast experimentation and uses **LangGraph/LangChain** and a **Chroma** vector store. All model and storage providers are interchangeable.

## Quick Overview
- **Two indexers**: OCR extraction with metadata enrichment and LLM-based extraction/splitting.
- **Retrieval**: 2-stage retriever with LLM compression for focused answers.
- **LangGraph Dev/Studio**: Run graphs locally via `langgraph dev` and control them visually.
- **Sample data**: CANCOM documents are already indexed in `.chroma_directory` and ready to use.

## Architecture
### Indexing Pipelines

#### OCR Indexer
Extracts text from PDF pages (PNG images), enriches it with LLM metadata, and persists it in Chroma.

**Diagram**
![UML: OCR-Indexer](/docs/index_ocr_uml.png)

**Studio View**
![Studio: OCR-Indexer](/docs/ocr_indexer_studio.png)

#### LLM Indexer
Uses an LLM for text extraction and chunking, adds metadata, and writes to Chroma.

**Diagram**
![UML: LLM-Indexer](/docs/index_llm_uml.png)

**Studio View**
![Studio: LLM-Indexer](/docs/llm_indexer_studio.png)

### Retrieval Process (2-Stage with Compression)
- Initial ranking via vector similarity, followed by LLM compression on relevant passages.
- Supports multilingual queries and can target both OCR and LLM indexes.

**Diagram**
![UML: Retriever](/docs/retriever_uml.png)


**Studio View**
![Studio: Retriever](/docs/retriever_studio.png)

## Prerequisites
- **Python 3.12** (recommended) and `virtualenv` or `venv`.
- **poppler** for `pdf2image` (set the path in `.env` as `POPLER_PATH` if needed; Windows build: https://github.com/oschwartz10612/poppler-windows/releases/).
- Provide API keys via `.env` (at least `OPENAI_API_KEY`; optionally `LANGSMITH_API_KEY`).

## Installation & Startup
```bash
python -m venv .venv          # alternatively: py -3.12 -m venv .venv
source .venv/bin/activate     # Windows: .venv\Scripts\activate
pip install -e .[dev]
langgraph dev                 # starts the local LangGraph Dev/Studio interface
```

## Running Graphs in LangGraph Studio
1. **Choose a graph:** Switch between `index_graph` (OCR/LLM index) and `retrieval_graph` in the UI.
2. **Set parameters:** Adjust `collection_id`, `doc_id`, and optionally `chunking_config` to your data.
3. **Start run:** Execute the desired node in the Studio view or trigger the entire graph.

### Example Calls
**Retrieval Graph** – use existing collection `./data/DB_ZB25.pdf`:
- `collection_id`: `DB_ZB`
- `doc_id`: `DB_ZB_S55` (`95776bb8-7907-486c-b1fb-04e456c44e2c`)
- `query` examples:
  - "What is the DB doing regarding sustainability?"
  - "How many employees does the DB Group have worldwide?"

**Indexers** – existing collections (already stored in `.chroma_directory`):
- **LLM Indexer** `collection_id: Cancom_LLM`
  - `doc_id: Cancom_240514`, `path: ./data/Cancom/240514_CANCOM_Zwischenmitteilung.pdf`
  - `doc_id: Cancom_20241112`, `path: ./data/Cancom/20241112_CANCOM_Zwischenmitteilung.pdf`
- **OCR Indexer** `collection_id: Cancom_OCR`
  - `doc_id: Cancom_240514`, `path: ./data/Cancom/240514_CANCOM_Zwischenmitteilung.pdf`
  - `doc_id: Cancom_20241112`, `path: ./data/Cancom/20241112_CANCOM_Zwischenmitteilung.pdf`

**Retrieval Queries**
- Query entire collection: `collection_id = Cancom_LLM` or `Cancom_OCR`, `doc_id = None`
  - Example question: "How does CANCOM describe the impact of acquiring the KBC / CANCOM Austria Group on revenue, gross profit, and EBITDA in the Q1 2024 and Q3 2024 interim reports?"
- Query a single document: `collection_id = Cancom_LLM/OCR`, `doc_id = Cancom_240514`
  - Example questions:
    - "Where is Cancom SE located and what phone number can they be reached at?" (evidence page 13)
    - "What is the percentage and absolute difference in inventories between 12/31/2023 and 03/31/2024?" (evidence page 18)

## Operations and Troubleshooting Notes
- **Set language:** Choose the search language to match the document language, including for multimodal embeddings.
- **Extraction:** Each segment metadata entry contains a language tag; models should answer in that language.
- **Rate limits:** Different models can have their own limits; optionally configure a rate limiter per provider (OpenAI limits: <https://platform.openai.com/settings/organization/limits>).
- **Logging:** Exceptions from the extractor are logged and returned in the state.

### Known Limitations
- Large, densely described pages can cause `LengthFinishReasonError` because PNG + prompt exceed model length.
- The OCR indexer's `extract_text_node` currently processes table text; combined with `extract_tables` this can lead to duplicate segments.
- Prompts are generic and should be adapted for new domains.

### Ideas for Further Development
- Optional LLM enrichment in the OCR graph.
- Alternative 1-stage retriever.
- Write similarity score back into document metadata.
- Prompt optimization and benchmarking.
- Evaluation on various test datasets.
