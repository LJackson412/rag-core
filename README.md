# RAG App

A modular **Retrieval-Augmented Generation (RAG)** stack with an OCR-based indexing pipeline and a two-stage retrieval process with LLM compression. The setup is designed for fast experimentation and uses **LangGraph/LangChain** and a **Chroma** vector store. All model and storage providers are interchangeable.

## Quick Overview
- **OCR indexer**: OCR extraction with metadata enrichment.
- **Retrieval**: 2-stage retriever with LLM compression for focused answers.
- **LangGraph Dev/Studio**: Run graphs locally via `langgraph dev` and control them visually.
- **Sample data**: CANCOM documents are already indexed in `.chroma_directory` and ready to use.

## Architecture
### Indexing Pipelines

#### OCR Indexer
Extracts text from PDF pages (PNG images), enriches it with LLM metadata, and persists it in Chroma.

**Diagram**
![UML: OCR-Indexer](/docs/index_ocr_uml.png)

**Studio View**
![Studio: OCR-Indexer](/docs/ocr_indexer_studio.png)

### Retrieval Process (2-Stage with Compression)
- Initial ranking via vector similarity, followed by LLM compression on relevant passages.
- Supports multilingual queries and targets the OCR index.

**Diagram**
![UML: Retriever](/docs/retriever_uml.png)


**Studio View**
![Studio: Retriever](/docs/retriever_studio.png)

## Prerequisites
- **Python 3.12** (recommended) and `virtualenv` or `venv`.
- **poppler** for `pdf2image` (set the path in `.env` as `POPLER_PATH` if needed; Windows build: https://github.com/oschwartz10612/poppler-windows/releases/).
- Provide API keys via `.env` (at least `OPENAI_API_KEY`; optionally `LANGSMITH_API_KEY`).

## Installation & Startup
```bash
python -m venv .venv          # alternatively: py -3.12 -m venv .venv
source .venv/bin/activate     # Windows: .venv\Scripts\activate
pip install -e .[dev]
langgraph dev                 # starts the local LangGraph Dev/Studio interface
```

## Running Graphs in LangGraph Studio
1. **Choose a graph:** Switch between `index_graph` (OCR index) and `retrieval_graph` in the UI.
2. **Set parameters:** Adjust `collection_id`, `doc_id`, and optionally `chunking_config` to your data.
3. **Start run:** Execute the desired node in the Studio view or trigger the entire graph.

### Example Calls
./data/Test/Test.pdf
./data/Test/Test.csv
./data/Test/Test.docx
./data/Test/Test.xlsx
./data/Test/Test.png

**Indexers** â€“ existing collections (already stored in `.chroma_directory`):
- **OCR Indexer** `collection_id: Cancom_OCR`
  - `doc_id: Cancom_240514`, `path: ./data/Cancom/240514_CANCOM_Zwischenmitteilung.pdf`
  - `doc_id: Cancom_20241112`, `path: ./data/Cancom/20241112_CANCOM_Zwischenmitteilung.pdf`

**Retrieval Queries**
- Query entire collection: `collection_id = Cancom_OCR`, `doc_id = None`
  - Example question: "How does CANCOM describe the impact of acquiring the KBC / CANCOM Austria Group on revenue, gross profit, and EBITDA in the Q1 2024 and Q3 2024 interim reports?"
- Query a single document: `collection_id = Cancom_OCR`, `doc_id = Cancom_240514`
  - Example questions:
    - "Where is Cancom SE located and what phone number can they be reached at?" (evidence page 13)
    - "What is the percentage and absolute difference in inventories between 12/31/2023 and 03/31/2024?" (evidence page 18)

### OCR indexing modes
- `all` (default): Enrich text, image, and table segments before saving. Retrieval-summary generated by llm is used for embedding
- `none`: Skip all LLM enrichment and save segments directly. Extracted text is used from loader
- `imgs`: Enrich only image segments; text and table segments are saved without LLM enrichment.


## Operations and Troubleshooting Notes
- **Set language:** Choose the search language to match the document language, including for multimodal embeddings.
- **Extraction:** Each segment metadata entry contains a language tag; models should answer in that language.
- **Rate limits:** Different models can have their own limits; optionally configure a rate limiter per provider (OpenAI limits: <https://platform.openai.com/settings/organization/limits>).
- **Logging:** Exceptions from the extractor are logged and returned in the state.

### Known Limitations
- Large, densely described pages can cause `LengthFinishReasonError` because PNG + prompt exceed model length.
- The OCR indexer's `extract_text_node` currently processes table text; combined with `extract_tables` this can lead to duplicate segments.
- Prompts are generic and should be adapted for new domains.

### Ideas for Further Development
- Optional LLM enrichment in the OCR graph.
- Alternative 1-stage retriever.
- Write similarity score back into document metadata.
- Prompt optimization and benchmarking.
- Evaluation on various test datasets.
